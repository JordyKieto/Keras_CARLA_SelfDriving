{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ee2e180",
      "metadata": {
        "scrolled": true,
        "id": "8ee2e180"
      },
      "outputs": [],
      "source": [
        "# Package installations\n",
        "# !pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOxqd2YqCYxN",
        "outputId": "3a0841fc-20ee-40b5-d2f9-6924233c6d35"
      },
      "id": "OOxqd2YqCYxN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "536ee381",
      "metadata": {
        "id": "536ee381"
      },
      "outputs": [],
      "source": [
        "# Package imports\n",
        "\n",
        "import math\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras.optimizers import AdamW\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import Callback, EarlyStopping\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, concatenate, LSTM, Reshape, Lambda, GlobalAveragePooling2D, Activation\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import r2_score, mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import random\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "import pandas as pd\n",
        "import csv\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.debugging.disable_traceback_filtering()"
      ],
      "metadata": {
        "id": "sOlAKW-ZScHy"
      },
      "id": "sOlAKW-ZScHy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "home_dir = '/content'\n",
        "dataset_dir = f'{home_dir}/drive/MyDrive/Drift/Training/Data/dataset_004'\n",
        "temp_images_dir = f'{home_dir}/temp_images'"
      ],
      "metadata": {
        "id": "SCvQTwHiVHy9"
      },
      "id": "SCvQTwHiVHy9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with zipfile.ZipFile(f'{dataset_dir}/images.zip', 'r') as zip_ref:\n",
        "  zip_ref.extractall(temp_images_dir)"
      ],
      "metadata": {
        "id": "3vRcNBP0uILy"
      },
      "id": "3vRcNBP0uILy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomMetrics(Callback):\n",
        "    def __init__(self, val_generator, val_steps):\n",
        "        super().__init__()\n",
        "        self.val_generator = val_generator\n",
        "        self.val_steps = val_steps\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        val_labels = []\n",
        "        val_predictions = []\n",
        "\n",
        "        for i in range(self.val_steps):\n",
        "            val_data, val_label = self.val_generator[i]\n",
        "            val_pred = self.model.predict(val_data)\n",
        "            val_labels.append(val_label)\n",
        "            val_predictions.append(val_pred)\n",
        "\n",
        "        val_labels = np.concatenate(val_labels)\n",
        "        val_predictions = np.concatenate(val_predictions)\n",
        "\n",
        "        # Ensure shapes match\n",
        "        assert val_predictions.shape == val_labels.shape, f\"Shape mismatch: {val_predictions.shape} vs {val_labels.shape}\"\n",
        "\n",
        "        # Compute mean absolute error\n",
        "        mae = np.mean(np.abs(val_predictions - val_labels))\n",
        "\n",
        "        # Compute R2 score\n",
        "        r2 = r2_score(val_labels, val_predictions)\n",
        "\n",
        "        # Detailed logging\n",
        "        print(f'--- Epoch {epoch + 1} ---')\n",
        "        print(f'Loss: {logs[\"loss\"]:.4f}')\n",
        "        print(f'Validation Loss: {logs[\"val_loss\"]:.4f}')\n",
        "        print(f'Validation MAE: {logs[\"val_mae\"]:.4f}')\n",
        "        print(f'Mean Absolute Error (MAE): {mae:.4f}')\n",
        "        print(f'R2 Score: {r2:.4f}')\n",
        "        print('---------------------')\n"
      ],
      "metadata": {
        "id": "uB8hUVjMYxrp"
      },
      "id": "uB8hUVjMYxrp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DirectoryDataGenerator(Sequence):\n",
        "    def __init__(self, image_files, y_controls, csv, batch_size, image_shape, num_classes=None, shuffle=True):\n",
        "        self.y_controls = y_controls\n",
        "        self.batch_size = batch_size\n",
        "        self.image_shape = image_shape\n",
        "        self.num_classes = num_classes\n",
        "        self.shuffle = shuffle\n",
        "        self.file_list = image_files\n",
        "        self.csv_data = csv\n",
        "        self.on_epoch_end()\n",
        "\n",
        "        print(f\"Initialized DirectoryDataGenerator with {len(self.file_list)} images and {len(self.y_controls)} controls.\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.floor(len(self.file_list) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        batch_files = self.file_list[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "        X_images, y = self._data_generation(batch_files, index)\n",
        "        X_features = self._extract_features(index * self.batch_size, len(batch_files))\n",
        "        return [X_images, X_features], y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            # Combine file_list and y_controls into a single list of tuples\n",
        "            combined = list(zip(self.file_list, self.y_controls))\n",
        "\n",
        "            # Shuffle the combined list\n",
        "            np.random.shuffle(combined)\n",
        "\n",
        "            # Unzip the shuffled list back into file_list and y_controls\n",
        "            self.file_list, self.y_controls = zip(*combined)\n",
        "\n",
        "            # Convert back to list (zip returns tuples)\n",
        "            self.file_list = list(self.file_list)\n",
        "            self.y_controls = np.array(self.y_controls)\n",
        "\n",
        "            print(f\"Epoch ended with {len(self.file_list)} images and {len(self.y_controls)} controls.\")\n",
        "\n",
        "\n",
        "    def _data_generation(self, batch_files, index):\n",
        "        start_index = index * self.batch_size\n",
        "        end_index = start_index + self.batch_size\n",
        "        # print(f\"Generation index: {index}\")\n",
        "        # print(f\"start_index: {start_index}, end_index: {end_index}, y_controls length: {len(self.y_controls)}\")\n",
        "\n",
        "        # Adjust the end_index if it exceeds the length of y_controls\n",
        "        if end_index > len(self.y_controls):\n",
        "            end_index = len(self.y_controls)\n",
        "\n",
        "        current_batch_size = end_index - start_index\n",
        "\n",
        "        X = np.empty((self.batch_size, *self.image_shape))  # always create array with full batch size\n",
        "        y = np.empty((self.batch_size, self.y_controls.shape[1]))  # always create array with full batch size\n",
        "\n",
        "        actual_y = self.y_controls[start_index:end_index]\n",
        "        # print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n",
        "\n",
        "        for i, file_name in enumerate(batch_files[:current_batch_size]):\n",
        "            image = Image.open(file_name)\n",
        "            image = image.resize((self.image_shape[1], self.image_shape[0]))\n",
        "            image = np.array(image) / 255.0  # Normalize to [0, 1]\n",
        "\n",
        "            X[i,] = image\n",
        "\n",
        "        # Handle the case where the current batch is smaller than the batch size\n",
        "        if current_batch_size < self.batch_size:\n",
        "            X[current_batch_size:,] = 0  # pad the remaining batch with zeros or any other value\n",
        "            y[current_batch_size:,] = 0  # pad the remaining batch with zeros or any other value\n",
        "\n",
        "        y[:current_batch_size] = actual_y\n",
        "\n",
        "        return X, y\n",
        "\n",
        "\n",
        "    def _extract_features(self, start_index, batch_size):\n",
        "        features = []\n",
        "        for i in range(batch_size):\n",
        "            feature_row = self.csv_data.iloc[start_index + i].values  # Use iloc for row extraction\n",
        "            features.append(feature_row)\n",
        "        return np.array(features)\n"
      ],
      "metadata": {
        "id": "bgQfESLHo3Tl"
      },
      "id": "bgQfESLHo3Tl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom activation function to constrain the output\n",
        "def custom_activation(x):\n",
        "    # Apply sigmoid to throttle and brake to ensure [0, 1] range\n",
        "    throttle = tf.keras.activations.sigmoid(x[:, 0])\n",
        "    brake = tf.keras.activations.sigmoid(x[:, 2])\n",
        "\n",
        "    # Apply tanh to steer to ensure [-1, 1] range\n",
        "    steer = tf.keras.activations.tanh(x[:, 1])\n",
        "\n",
        "    # Apply sigmoid and then round to get boolean values for hand_brake, reverse, manual_gear_shift\n",
        "    hand_brake = tf.round(tf.keras.activations.sigmoid(x[:, 3]))\n",
        "    reverse = tf.round(tf.keras.activations.sigmoid(x[:, 4]))\n",
        "    manual_gear_shift = tf.round(tf.keras.activations.sigmoid(x[:, 5]))\n",
        "\n",
        "    # Apply linear activation to gear and then round to get integer values\n",
        "    gear = tf.round(x[:, 6])\n",
        "\n",
        "    # Concatenate all the processed components back into a single tensor\n",
        "    return tf.stack([throttle, steer, brake, hand_brake, reverse, manual_gear_shift, gear], axis=1)"
      ],
      "metadata": {
        "id": "8wEzKfu2wWGh"
      },
      "id": "8wEzKfu2wWGh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_shape = (600, 800, 4)  # Adjust based on your image dimensions\n",
        "y_controls = np.load(f'{dataset_dir}/y_controls.npy')  # Assuming y_controls is saved in a .npy file\n",
        "csv_path = f'{dataset_dir}/measurements.csv'  # Path to CSV file with additional features\n",
        "batch_size = 100  # Adjust batch size as needed\n",
        "num_classes = 7  # Assuming 7 outputs, adjust based on your use case\n",
        "\n",
        "print(f\"y_controls shape: {y_controls.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xX7SrgS9c5f_",
        "outputId": "2fbf8291-4641-48e0-c14d-08b329c88208"
      },
      "id": "xX7SrgS9c5f_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_controls shape: (11886, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the list of image files\n",
        "file_list = sorted(\n",
        "    [os.path.join(temp_images_dir + \"/images\", f) for f in os.listdir(temp_images_dir + \"/images\") if f.endswith('.png')],\n",
        "    key=lambda x: int(os.path.splitext(os.path.basename(x))[0])\n",
        ")\n",
        "\n",
        "print(f\"Total number of files: {len(file_list)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjkfLua4mudu",
        "outputId": "0bedfc77-8d04-4240-d8d8-7f08362c7b84"
      },
      "id": "zjkfLua4mudu",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of files: 11886\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Trim dataset\n",
        "\n",
        "# Ensure the number of files and y_controls match after trimming\n",
        "trim_amount = 1886\n",
        "\n",
        "file_list = file_list[:-trim_amount] # trim dataset\n",
        "y_controls = y_controls[:-trim_amount, :] # Trim dataset\n",
        "print(f\"trimmed y_controls shape: {y_controls.shape}\")\n",
        "print(f\"trimmed file_list shape: {len(file_list)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPqn5NQDnHaf",
        "outputId": "6913f877-cf49-46ef-f2a8-6c7dbf0091de"
      },
      "id": "LPqn5NQDnHaf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trimmed y_controls shape: (10000, 7)\n",
            "trimmed file_list shape: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "measurements = pd.read_csv(csv_path, header=None)\n",
        "print(f\"measurements shape: {measurements.shape}\")\n",
        "measurements = measurements.iloc[:-trim_amount, :]\n",
        "\n",
        "print(f\"measurements shape: {measurements.shape}\")\n",
        "\n",
        "# # Ensure that all arrays have the same length\n",
        "assert len(file_list) == len(y_controls) == len(measurements), \"All arrays must have the same length\"\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUGFIgZKQOCV",
        "outputId": "f26c8fbe-d458-4cf2-d4dc-88eee4e28a00"
      },
      "id": "AUGFIgZKQOCV",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "measurements shape: (11886, 6)\n",
            "measurements shape: (10000, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming the necessary imports and variable definitions are already done\n",
        "\n",
        "\n",
        "\n",
        "# Verify file counts\n",
        "print(f\"Total number of files: {len(file_list)}\")\n",
        "print(f\"Total number of labels: {len(y_controls)}\")\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "train_files, val_files, y_train, y_val, train_measurements, val_measurements = train_test_split(\n",
        "    file_list, y_controls, measurements, test_size=0.1, random_state=42\n",
        ")\n",
        "# Verify shapes after splitting\n",
        "print(f\"Train row count: {len(train_files)}, Train labels shape: {y_train.shape}\")\n",
        "print(f\"Validation row count: {len(val_files)}, Validation labels shape: {y_val.shape}\")\n",
        "\n",
        "# Create generators for training and validation\n",
        "# TODO renable shuffle on training generator\n",
        "train_generator = DirectoryDataGenerator(train_files, y_train, train_measurements, batch_size, image_shape, num_classes, shuffle=True)\n",
        "val_generator = DirectoryDataGenerator(val_files, y_val, val_measurements, batch_size, image_shape, num_classes, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JDr7qrGv5Fq",
        "outputId": "b37c8de6-2881-4e64-b146-ef2732c0788e"
      },
      "id": "-JDr7qrGv5Fq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of files: 10000\n",
            "Total number of labels: 10000\n",
            "Train row count: 9000, Train labels shape: (9000, 7)\n",
            "Validation row count: 1000, Validation labels shape: (1000, 7)\n",
            "Epoch ended with 9000 images and 9000 controls.\n",
            "Initialized DirectoryDataGenerator with 9000 images and 9000 controls.\n",
            "Initialized DirectoryDataGenerator with 1000 images and 1000 controls.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Image input branch\n",
        "image_input = Input(shape=(224, 224, 3), name='image_input')\n",
        "\n",
        "x = Conv2D(32, (3, 3), padding='same')(image_input)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "x = Conv2D(64, (3, 3), padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "x = Conv2D(128, (3, 3), padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "\n",
        "# Additional features input branch\n",
        "features_input = Input(shape=(6,), name='features_input')  # Adjust num_features based on your CSV data\n",
        "\n",
        "# Combine the outputs of the two branches\n",
        "combined = concatenate([x, features_input])\n",
        "\n",
        "# Fully connected layers after concatenation\n",
        "z = Dense(256, activation='relu')(combined)\n",
        "z = Dense(128, activation='relu')(z)\n",
        "z = Dense(64, activation='relu')(z)\n",
        "\n",
        "# Output Layer\n",
        "output = Dense(7, activation='linear')(z)  # Assuming 7 outputs\n",
        "\n",
        "# Apply custom activation for range constraints\n",
        "output = Lambda(custom_activation)(output)\n",
        "\n",
        "# Define the model\n",
        "model = Model(inputs=[image_input, features_input], outputs=output)"
      ],
      "metadata": {
        "id": "8g3laKNkQZVh"
      },
      "id": "8g3laKNkQZVh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "optimizer = AdamW(learning_rate=0.0001)\n",
        "metrics = [\n",
        "    'mae',\n",
        "    tf.keras.metrics.RootMeanSquaredError(),\n",
        "    # tf.keras.metrics.MeanAbsoluteError(),\n",
        "    # tf.keras.metrics.MeanSquaredError(),\n",
        "    # tf.keras.metrics.MeanAbsolutePercentageError(),\n",
        "    # tf.keras.metrics.MeanSquaredLogarithmicError(),\n",
        "    # tf.keras.metrics.CosineSimilarity(),\n",
        "]\n",
        "model.compile(optimizer=optimizer, loss='mse', metrics=metrics)\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n",
        "\n",
        "# Calculate the number of validation steps\n",
        "val_steps = len(val_generator)\n",
        "\n",
        "# Create an instance of the CustomMetrics callback with validation data\n",
        "custom_metrics = CustomMetrics(val_generator, val_steps)\n",
        "\n",
        "# Create an instance of the EarlyStopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train the model using the generator and the custom callbacks\n",
        "history = model.fit(train_generator, validation_data=val_generator, epochs=20, callbacks=[custom_metrics])"
      ],
      "metadata": {
        "id": "HvkfoSdPGzGV"
      },
      "id": "HvkfoSdPGzGV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model.save_weights('/content/drive/MyDrive/Drift/Training/Models/vehicle_control_model_015.h5')\n"
      ],
      "metadata": {
        "id": "IhoY-rXoeCgx"
      },
      "id": "IhoY-rXoeCgx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KSlxtc802VFB"
      },
      "id": "KSlxtc802VFB",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "history_visible": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}